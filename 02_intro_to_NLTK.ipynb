{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scskalicky/LING-226-vuw/blob/main/02_intro_to_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_vjnsOY-w-M"
      },
      "source": [
        "# Getting started with NLTK\n",
        "\n",
        "\n",
        "You'll notice that sections 1.1 and 1.2 of Chatper 1 in the NLTK Book contain instructions for how to install Python and NLTK on your computer. If you are using Google Collaboratory, these points are not relevant. However, you are still encouraged to read these sections for a better understanding of how Python and NLTK would work outside of Google Colab.\n",
        "\n",
        "*A few other notes*\n",
        "- Google Colab does not have the `>>>` prompt mentioned in the NLTK book - this is replaced by the code cells in Colab.\n",
        "- the `generate()` function will not work. \n",
        "- there are likely many other little things that won't work based on various updates to Python/NLTK and/or the use of Google Colab, such as plotting and other functions which come later in the book. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hPAJpD5_NyT"
      },
      "source": [
        "## Accessing NLTK on Google Colab\n",
        "\n",
        "- NLTK is already pre-installed in Google Colab. But NLTK requires a lot of additional resources which we need to download. In section 1.2 of Chapter 1, the NLTK book explains that to access these resources one should use `nltk.download()`. We will use the same function but will not see the graphical downloader shown in the book.\n",
        "\n",
        "- For instance, one of the very first lessons in NLTK section 1.2 asks you to use `from nltk.book import *`, which means import everything from `nltk.book` (the `*` means everything). However you will get an error if you try this in Colab because the `book` data has not yet been downloaded.\n",
        "\n",
        "- When you do not have the right resource to run a particular NLTK function, you will see an error which looks like this:\n",
        ">> ![error](https://drive.google.com/uc?id=1nt76M0KbiLueTYHb72HSFnREC9_1DsM4)\n",
        "\n",
        "- If you see this error, don't panic! It just means you are missing a specific resource. In this example, the part that I selected in yellow is what is missing - in this case it is the resource `stopwords`. All you need to do is ask Colab to download the resource using the `nltk.download()` function. Because the Colab notebook is running on a temporary server, you will need to repeat this each time you connect to a new sessino. Fortunately, it does not take very long to download the data. \n",
        "\n",
        "You can specify which resources you need by passing each resource as a `string` inside a single `list` (i.e., inside square brackets `[]`). In the example below, I include a wide range of specific resources which you will need for the first chapter of NLTK. \n",
        "\n",
        "```\n",
        "# define a list of resources and save to variable\n",
        "nltk_resources = ['gutenberg', 'genesis', 'inaugural', 'nps_chat', 'webtext',\n",
        " 'treebank', 'stopwords', 'punkt', 'brown', 'reuters', 'udhr', 'words', 'names', 'cmudict', 'swadesh', 'wordnet', 'state_union']\n",
        "\n",
        "# Pass the list to nltk.download(), which will then download each resource\n",
        "nltk.download(nltk_resources)\n",
        "```\n",
        "\n",
        "Once you have sorted out your ability to access NLTK resources, you are ready to go through the rest of the notebook lessons. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpUZxNNO-tL3"
      },
      "outputs": [],
      "source": [
        "# import the main nltk module\n",
        "import nltk\n",
        "\n",
        "# create a list of resources we will need for this notebook\n",
        "nltk_resources = ['gutenberg', 'genesis', 'inaugural', 'nps_chat', 'webtext', 'treebank', 'stopwords', 'punkt', 'brown', 'reuters', 'udhr', 'words', 'names', 'cmudict', 'swadesh', 'wordnet', 'state_union']\n",
        "\n",
        "# download them\n",
        "nltk.download(nltk_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muY7BdQQDlq4"
      },
      "source": [
        "# Searching Text\n",
        "\n",
        "Chapter 1 asks you to load in a series of books and corpora which are stored in NLTK as examples. Take a moment to look at the names of the files - some are single books and movie scripts, while others are different corpora. What is the difference between the two? A book is simply a stand-alone book, whereas a corpus is a large collection of text from similar texts/documents, which can be longer or shorter than a single book. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPoI-04vK23i"
      },
      "outputs": [],
      "source": [
        "# import everything from ntlk.book()\n",
        "from nltk.book import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWt6zMhZO_d4"
      },
      "source": [
        "## Concordances\n",
        "\n",
        "NLTK starts off with concordances, which is a method that draws from corpus linguistics to analyse the function of different words in texts. This method is fundamental for performing corpus analysis because a concordance will let you see a single word or patterns of words **in context** of the surrounding words. \n",
        "\n",
        "The example in the NLTK book is to search for the word `monstrous` in *Moby Dick*. \n",
        "\n",
        "Here are some other collocations I searched for based on my own guesses about what you might find in the differnt corpora. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgIRw-NLNanl"
      },
      "outputs": [],
      "source": [
        "# search for \"color\" in Holy Grail\n",
        "text6.concordance('color')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwejNvI2Pco2"
      },
      "outputs": [],
      "source": [
        "# search for \"like\" in webchat\n",
        "text5.concordance('like')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvuLwCbGP2G1"
      },
      "outputs": [],
      "source": [
        "# search for 'looking' in the personals corpus\n",
        "text8.concordance('looking') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw_4SPh9QcKc"
      },
      "source": [
        "# Comparing words\n",
        "\n",
        "What you probably noticed is that words are used in specific ways in different corpora. This relatively simple anlaysis has thus already told us something about the way language works: context determines the way words are used and understood. Corpus linguistic anlaysis is thus a crucial way to gain a better understanding of word meanings and language use.\n",
        "\n",
        "\n",
        "The `.similar()` and `.common_contexts()` methods allow you to find words that are used in the same contexts. This means words which occur before/after the same other words. For example, in the following two sentences the words \"truck\" and \"apple\" are similar because they both occur after the word \"red\":\n",
        "\n",
        "- A big red truck\n",
        "- A big red apple\n",
        "\n",
        "\n",
        "Try testing the word \"hello\" using the `.similar()` method in different corpora. The output that you see represents words that are used in similar contexts are your input word. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Yzjt9XgRyDv"
      },
      "outputs": [],
      "source": [
        "# which words occur in the same contexts as 'hello' in Monty Python\n",
        "text6.similar('hello')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42WwKcGvSJi2"
      },
      "outputs": [],
      "source": [
        "# and what about in the webchat corpus?\n",
        "text5.similar('hello')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITaNH55-STr_"
      },
      "source": [
        "The `.common_contexts()` method allows you to compare two words in the same text. The book uses the example of testing `monstrous` and `very` in Moby Dick. The book asks you to pick two words of your own and compare them. If you're like me, you will see that many times you have no results because the words you searched for do not occur in the corpus or do not have any common contexts - this further demonstrates how we can predict the types of words based on our knowldge of the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3kRvLGDSoDY"
      },
      "outputs": [],
      "source": [
        "# do hello and goodbye have simlar contexts in the webchat corpus?\n",
        "text5.common_contexts(['hello', 'goodbye'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptdcp6ZcS0_o"
      },
      "outputs": [],
      "source": [
        "# what about 'hi' and 'bye' in the webchat corpus? \n",
        "text5.common_contexts(['hi', 'bye'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3povNiVTgw1"
      },
      "outputs": [],
      "source": [
        "# how about \"hi\" and \"bye\" in the personals?\n",
        "text8.common_contexts(['hi', 'bye'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI5tcSgM97fw"
      },
      "outputs": [],
      "source": [
        "# these words in moby dick?\n",
        "text1.common_contexts(['white', 'whale'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twABRQEGTeip"
      },
      "source": [
        "If we wanted to make sure the words are actually in the corpus before running the function, we could wrap it in an `if` conditional statement and check the `.vocab()` method of the corpus (which is a list of the words in the corpus!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja4ltQ5gPpNN"
      },
      "outputs": [],
      "source": [
        "# check if a word is are in the corpus text\n",
        "'like' in text5.vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4bLVmAjT8cX"
      },
      "outputs": [],
      "source": [
        "'knight' in text6.vocab()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Your Turn**\n",
        "\n",
        "1. Spend a few moments using the `.concordance()` function to search for different words in the texts. See if you can find any interesting examples and share with the class.  \n",
        "\n",
        "2. After looking through some concordances, play with the `.similar()` and `.common_contexts()` functions to see if you can find words used in similar contexts. \n",
        "\n",
        "3. What can this analysis tell us, if anything, about the nature of the different texts? \n",
        "\n"
      ],
      "metadata": {
        "id": "ndhkAGve8xv1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}